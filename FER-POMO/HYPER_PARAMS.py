TSP_SIZE = 20  # TSP number of nodes

# Hyper-Parameters
TOTAL_EPOCH = 100
CHECKPOINT_EPOCHS = 1

TRAIN_DATASET_SIZE = 2  # 100*1000
TEST_DATASET_SIZE = 3  # 10*1000
TRAIN_BATCH_SIZE = 2  # 64
TEST_BATCH_SIZE = 3  # 256

EMBEDDING_DIM = 128
KEY_DIM = 16  # Length of q, k, v of EACH attention head
HEAD_NUM = 8
ENCODER_LAYER_NUM = 6
FF_HIDDEN_DIM = 512
LOGIT_CLIPPING = 10  # (C in the paper)

GAMMA = 0.999
N_STEP = 5
T_TRAIN = 100
T_MAX = 200  # 200
MAX_POOL = TSP_SIZE // 5
MAX_GRAD_NORM = 1.0
HIDDEN_EDGE_DIM = 32
ALPHA = 0.2
HIDDEN_DIM = 128

ACTOR_LEARNING_RATE = 1e-4
ACTOR_WEIGHT_DECAY = 0.988  # 1e-6
CRITIC_LEARNING_RATE = 5e-5
CRITIC_WEIGHT_DECAY = 0.988
LOG_STEP = 10

LR_DECAY_EPOCH = 1
LR_DECAY_GAMMA = 0.988  # 1.00

# Logging
LOG_PERIOD_SEC = 15
